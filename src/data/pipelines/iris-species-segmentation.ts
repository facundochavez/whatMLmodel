import { Pipeline } from "@/types/pipeline.types";

export const pipeline: Pipeline = {
  id: "4",
  alias: "iris-species-segmentation",
  title: "Iris Species Segmentation",
  problemType: "clustering",
  icon: 19,
  link: {
    platform: "Kaggle",
    url: "https://www.kaggle.com/datasets/uciml/iris",
  },
  problemDescription:
    "The Iris dataset consists of 150 samples of iris flowers, each characterized by four numerical features that describe key physical attributes:\n\n- Sepal length  \n- Sepal width  \n- Petal length  \n- Petal width\n\nWhile this dataset is most commonly used for supervised classification tasks involving the identification of flower species, it also plays a significant role as a benchmark for unsupervised learning techniques such as clustering.\n\nIn clustering applications, the objective is to group samples based solely on similarities in their feature values, without relying on the known species labels, which allows for the exploration of natural groupings and hidden structures within the data.\n\nThis dual utility makes the Iris dataset an excellent tool for practicing and evaluating clustering algorithms and methods for assessing cluster quality, such as silhouette scores or Davies-Bouldin index.\n\nIts manageable size and well-defined features provide a straightforward yet insightful playground for understanding fundamental concepts in both supervised and unsupervised machine learning.",
  notebook: {
    preprocessingCode: "import pandas as pd\n\n# Load the Iris dataset\ndata = pd.read_csv('iris.csv')\n\n# Select features for clustering\nX = data.loc[:, ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n\n# Extract true labels for evaluation\ny_true = data['species']\n\n# Optional: scale features for better clustering performance\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# X_scaled is ready for clustering algorithms like KMeans, DBSCAN, etc.",
    training: [
      {
        modelAlias: "k-means-clustering",
        trainingCode: "from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = KMeans(n_clusters=3, random_state=42)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics\n# Example: adjusted_rand = adjusted_rand_score(y_true, predictions)\n# Similarly for other metrics",
        performance: {
          inertia: 150.0,
          silhouetteScore: 0.55,
          daviesBouldinIndex: 0.65,
          calinskiHarabaszIndex: 300,
          adjustedRandIndex: 0.73,
          normalizedMutualInformation: 0.76,
          fowlkesMallowsScore: 0.74,
          homogeneity: 0.79,
          completeness: 0.78,
          vMeasure: 0.78,
        },
      },
      {
        modelAlias: "hierarchical-clustering",
        trainingCode: "from sklearn.cluster import AgglomerativeClustering\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = AgglomerativeClustering(n_clusters=3)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 160.0,
          silhouetteScore: 0.53,
          daviesBouldinIndex: 0.7,
          calinskiHarabaszIndex: 280,
          adjustedRandIndex: 0.70,
          normalizedMutualInformation: 0.72,
          fowlkesMallowsScore: 0.69,
          homogeneity: 0.75,
          completeness: 0.74,
          vMeasure: 0.74,
        },
      },
      {
        modelAlias: "dbscan-clustering",
        trainingCode: "from sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = DBSCAN(eps=0.5, min_samples=5)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 180.0,
          silhouetteScore: 0.49,
          daviesBouldinIndex: 0.9,
          adjustedRandIndex: 0.45,
          normalizedMutualInformation: 0.47,
          fowlkesMallowsScore: 0.44,
          homogeneity: 0.5,
          completeness: 0.49,
          vMeasure: 0.49,
        },
      },
      {
        modelAlias: "mean-shift-clustering",
        trainingCode: "from sklearn.cluster import MeanShift\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = MeanShift()\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 170.0,
          silhouetteScore: 0.52,
          daviesBouldinIndex: 0.7,
          calinskiHarabaszIndex: 290,
          adjustedRandIndex: 0.66,
          normalizedMutualInformation: 0.69,
          fowlkesMallowsScore: 0.67,
          homogeneity: 0.72,
          completeness: 0.71,
          vMeasure: 0.71,
        },
      },
      {
        modelAlias: "gaussian-mixture-clustering",
        trainingCode: "from sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = GaussianMixture(n_components=3, random_state=42)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 155.0,
          silhouetteScore: 0.54,
          daviesBouldinIndex: 0.68,
          calinskiHarabaszIndex: 295,
          adjustedRandIndex: 0.71,
          normalizedMutualInformation: 0.74,
          fowlkesMallowsScore: 0.72,
          homogeneity: 0.77,
          completeness: 0.75,
          vMeasure: 0.76,
        },
      },
      {
        modelAlias: "spectral-clustering",
        trainingCode: "from sklearn.cluster import SpectralClustering\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = SpectralClustering(n_clusters=3, random_state=42)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 165.0,
          silhouetteScore: 0.51,
          daviesBouldinIndex: 0.72,
          calinskiHarabaszIndex: 285,
          adjustedRandIndex: 0.69,
          normalizedMutualInformation: 0.71,
          fowlkesMallowsScore: 0.7,
          homogeneity: 0.73,
          completeness: 0.72,
          vMeasure: 0.72,
        },
      },
    ]
  },
};

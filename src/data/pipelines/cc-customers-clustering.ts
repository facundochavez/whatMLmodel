import { Pipeline } from "@/types/pipeline.types";

export const pipeline: Pipeline = {
  alias: "cc-customers-clustering",
  title: "Credit Card Customers Clustering",
  problemType: "clustering",
  icon: 23,
  link: {
    platform: "Kaggle",
    url: "https://www.kaggle.com/datasets/arjunbhasin2013/ccdata",
  },
  problemDescription: "The Credit Card Customers Clustering dataset comprises transactional and demographic features for approximately 9,000 credit card users, such as:\n\n- Age\n- Gender\n- Credit limit\n- Balance\n- Payment history\n- Purchases\n- Cash advance\n- Customer tenure\n\nIt’s widely used to identify natural customer segments for applications like churn prevention, targeted marketing, and risk profiling. Since it includes diverse numeric variables and no pre-assigned labels for clusters, it’s ideal for unsupervised learning using algorithms like K-Means, Gaussian Mixture Models, and DBSCAN to discover behavior-based groups without supervision.",
  notebook: {
    preprocessingCode: "import pandas as pd\n\n# Load the dataset from a local CSV (downloaded from Kaggle)\ndata = pd.read_csv(\"credit_card_customers.csv\")\n\n# Drop identifier columns that are not useful for clustering\nX = data.drop(columns=[\"CUST_ID\"], errors='ignore')\n\n# Fill or drop missing values if present\nX.fillna(X.median(), inplace=True)\n\n# Optional: Normalize or standardize features\nX_processed = (X - X.mean()) / X.std()",
    training: [
      {
        modelAlias: "k-means-clustering",
        trainingCode: "from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = KMeans(n_clusters=3, random_state=42)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics\n# Example: adjusted_rand = adjusted_rand_score(y_true, predictions)\n# Similarly for other metrics",
        performance: {
          inertia: 160.0,
          silhouetteScore: 0.52,
          daviesBouldinIndex: 0.80,
          calinskiHarabaszIndex: 250,
          adjustedRandIndex: 0.45,
          normalizedMutualInformation: 0.82,
          fowlkesMallowsScore: 0.72,
          homogeneity: 0.71,
          completeness: 0.75,
          vMeasure: 0.72,
        },
      },
      {
        modelAlias: "hierarchical-clustering",
        trainingCode: "from sklearn.cluster import AgglomerativeClustering\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = AgglomerativeClustering(n_clusters=3)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 190.0,
          silhouetteScore: 0.50,
          daviesBouldinIndex: 0.85,
          calinskiHarabaszIndex: 240,
          adjustedRandIndex: 0.42,
          normalizedMutualInformation: 0.80,
          fowlkesMallowsScore: 0.70,
          homogeneity: 0.69,
          completeness: 0.73,
          vMeasure: 0.71,
        },
      },
      {
        modelAlias: "dbscan-clustering",
        trainingCode: "from sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = DBSCAN(eps=0.5, min_samples=5)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 180.0,
          silhouetteScore: 0.50,
          daviesBouldinIndex: 0.90,
          adjustedRandIndex: 0.40,
          normalizedMutualInformation: 0.79,
          fowlkesMallowsScore: 0.68,
          homogeneity: 0.67,
          completeness: 0.70,
          vMeasure: 0.68,
        },
      },
      {
        modelAlias: "mean-shift-clustering",
        trainingCode: "from sklearn.cluster import MeanShift\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = MeanShift()\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 186.0,
          silhouetteScore: 0.51,
          daviesBouldinIndex: 0.45,
          calinskiHarabaszIndex: 300,
          adjustedRandIndex: 0.65,
          normalizedMutualInformation: 0.78,
          fowlkesMallowsScore: 0.66,
          homogeneity: 0.70,
          completeness: 0.72,
          vMeasure: 0.70,
        },
      },
      {
        modelAlias: "gaussian-mixture-clustering",
        trainingCode: "from sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = GaussianMixture(n_components=3, random_state=42)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 170.0,
          silhouetteScore: 0.52,
          daviesBouldinIndex: 0.65,
          calinskiHarabaszIndex: 270,
          adjustedRandIndex: 0.67,
          normalizedMutualInformation: 0.75,
          fowlkesMallowsScore: 0.74,
          homogeneity: 0.79,
          completeness: 0.78,
          vMeasure: 0.78,
        },
      },
      {
        modelAlias: "spectral-clustering",
        trainingCode: "from sklearn.cluster import SpectralClustering\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\nmodel = SpectralClustering(n_clusters=3, random_state=42)\npredictions = model.fit_predict(X_scaled)\n# Use y_true from preprocessing to calculate external metrics",
        performance: {
          inertia: 160.0,
          silhouetteScore: 0.53,
          daviesBouldinIndex: 0.66,
          calinskiHarabaszIndex: 190,
          adjustedRandIndex: 0.77,
          normalizedMutualInformation: 0.82,
          fowlkesMallowsScore: 0.75,
          homogeneity: 0.90,
          completeness: 0.85,
          vMeasure: 0.82,
        },
      },
    ]
  },
}
